{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b829a69-fc63-491b-81ca-a32f6625632f",
   "metadata": {},
   "source": [
    "# Dataset Example-based explanations\n",
    "\n",
    "For a batch of $B$ sequences of length $L$, each sampled from a different episode, the observations that maximize the activity of each categorical distribution are displayed, for a trained model.\n",
    "\n",
    "## Strategy\n",
    "\n",
    "1. Sample a batch of shape ${[}B,L,C,K{]}$ of $B$ observations, each denoting a rollout of length $L$, and compute the corresponding RSSM activations, denoted by $C$ categorical distributions with $K$ classes each.\n",
    "2. Flatten the batched activations to a matrix of shape ${[}BLC,K{]}$, so that exampled-based explanations can be generated independent from the specific class $C$.\n",
    "3. Apply Non-negative Matrix Factorization to the resulting matrix, with rank $r$.\n",
    "4. For each rollout of length $L$, highlight the most important observations, according to the magnitude ($\\ell_2$-norm) of the corresponding activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c129c8-12e2-4399-8a3c-5cb3cdfcb5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchnmf.nmf import NMF\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from dreamerv2.models.rssm import RSSMDiscState\n",
    "from dreamerv2.training.config import MinAtarConfig\n",
    "from dreamerv2.training.evaluator import Evaluator\n",
    "from dreamerv2.utils.wrapper import GymMinAtar, OneHotAction, freewayPOMDP\n",
    "\n",
    "env_name = \"freeway\"\n",
    "exp_id = \"0_pomdp\"\n",
    "device = \"cuda:0\"\n",
    "rank=10\n",
    "\n",
    "ACTIONS = {\n",
    "    0: \"STAY\",\n",
    "    1: \"UP\",\n",
    "    2: \"DOWN\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4aece-5d78-4aca-a932-b9817b21eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = freewayPOMDP(OneHotAction(GymMinAtar(env_name)))\n",
    "result_dir = os.path.join(\"../results_official\", f\"{env_name}_{exp_id}\")\n",
    "model_dir = os.path.join(result_dir, \"models\")\n",
    "f = \"models_best.pth\"\n",
    "\n",
    "config = MinAtarConfig(\n",
    "    env=env_name,\n",
    "    obs_shape=env.observation_space.shape,\n",
    "    action_size=env.action_space.shape[0],\n",
    "    obs_dtype=bool,\n",
    "    action_dtype=np.float32,\n",
    "    model_dir=model_dir,\n",
    "    eval_episode=10,\n",
    "    eval_render=False,\n",
    ")\n",
    "\n",
    "evaluator = Evaluator(config, device)\n",
    "evaluator.load_model(evaluator.config, os.path.join(model_dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70b6a4-0d6d-4fd6-8376-2b9d1c678e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "done = False\n",
    "history = []\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Produce always same episode\n",
    "env = freewayPOMDP(OneHotAction(GymMinAtar(env_name)))\n",
    "env.env.env.seed(212)\n",
    "torch.manual_seed(313)\n",
    "\n",
    "# [2, 10, 10]\n",
    "obs = env.reset()\n",
    "\n",
    "# Initial RSSM state (all zeros):\n",
    "# state.deter [1, 200]\n",
    "# state.logit [1, 400] (20 categegoricals, 20 classes each)\n",
    "# state.stoch [1, 400] (20 one-hot samples, sampled from logit)\n",
    "prev_rssm_state = evaluator.RSSM._init_rssm_state(batch_size=1)\n",
    "\n",
    "# [1, 3]\n",
    "prev_action = torch.zeros(1, evaluator.action_size).to(evaluator.device)\n",
    "\n",
    "for _ in range(config.seq_len):\n",
    "    # Embed observation, [1, 200]\n",
    "    embed = evaluator.ObsEncoder(\n",
    "        torch.tensor(obs, dtype=torch.float32).unsqueeze(0).to(evaluator.device)\n",
    "    )\n",
    "\n",
    "    # During evaluation, use the posterior state, i.e. the one obtained using the current observation.\n",
    "    _, posterior_rssm_state = evaluator.RSSM.rssm_observe(\n",
    "        embed, prev_action, not done, prev_rssm_state\n",
    "    )\n",
    "\n",
    "    # Concat deter+stoch state [1, 600]\n",
    "    model_state = evaluator.RSSM.get_model_state(posterior_rssm_state)\n",
    "\n",
    "    # The history consists of:\n",
    "    # current obs         o_t\n",
    "    # current state       h_t, s_t\n",
    "    # predicted action    a_t\n",
    "    # internal move timer (will the action actually have effect?)\n",
    "    action, _ = evaluator.ActionModel(model_state)\n",
    "    \n",
    "    history.append(\n",
    "        (\n",
    "            obs,\n",
    "            RSSMDiscState(\n",
    "                posterior_rssm_state.logit.cpu().squeeze(0).reshape(20, 20),\n",
    "                posterior_rssm_state.stoch.cpu().squeeze(0).reshape(20, 20),\n",
    "                posterior_rssm_state.deter.cpu().squeeze(0),\n",
    "            ),\n",
    "            action.squeeze(0).cpu().numpy(),\n",
    "            env.env.env.env.env.move_timer == 0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    obs, reward, done, _ = env.step(action.squeeze(0).cpu().numpy())\n",
    "    score += reward\n",
    "    prev_rssm_state = posterior_rssm_state\n",
    "    prev_action = action\n",
    "\n",
    "score, len(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66c165-4b32-4ace-999d-554c8eeba41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack logits\n",
    "logits_list = torch.stack([ state[1].logit for state in history ], dim=0).to(device)\n",
    "\n",
    "# reshape logits\n",
    "logits = logits.reshape(-1, config.rssm_info.category_size)\n",
    "\n",
    "# factorize matrix\n",
    "model = NMF(logits.t().shape, rank=rank).to(device)\n",
    "model.fit(logits.t())\n",
    "\n",
    "# compute l2-norm of each column of model.H.t()\n",
    "activations = torch.norm(model.W * model.H.t(), p=2, dim=1).reshape(-1, 20)\n",
    "max_act = torch.max(activations.view(-1))\n",
    "activations = (activations / max_act).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be472928-6820-4108-951e-1b31bfbb1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_freeway(obs):\n",
    "    buf = np.zeros((10, 10, 3), dtype=np.uint8)\n",
    "    buf[obs[0]] = (255, 255, 255)\n",
    "    buf[obs[1]] = (255, 0, 0)\n",
    "    return buf\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(len(history), 4, figsize=(12, 3 * len(history)))\n",
    "axs[0, 0].set_title(\"Environment $o_t$\")\n",
    "axs[0, 1].set_title(\"Categoricals\")\n",
    "axs[0, 2].set_title(\"Sampled stoch state $s_t$\")\n",
    "axs[0, 3].set_title(\"Activity\")\n",
    "\n",
    "for t, axs_row in enumerate(axs):\n",
    "    obs, posterior_rssm_state, action, has_effect = history[t]\n",
    "\n",
    "    ax = axs_row[0]\n",
    "    ax.imshow(render_freeway(obs))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel(f\"Step {t}\")\n",
    "    ax.legend(\n",
    "        [],\n",
    "        loc=\"upper right\",\n",
    "        title=(\n",
    "            # If the action is in () it means that it will\n",
    "            # actually have no effect due to the game timer.\n",
    "            f\"Next {ACTIONS[action.argmax()]}\"\n",
    "            if has_effect\n",
    "            else f\"Next ({ACTIONS[action.argmax()]})\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    ax = axs_row[1]\n",
    "    ax.imshow(posterior_rssm_state.logit.softmax(-1).numpy(), vmin=0, vmax=1)\n",
    "    ax.set_xticks([0, 10])\n",
    "    ax.set_yticks([0, 10])\n",
    "    e = (\n",
    "        torch.distributions.Categorical(logits=posterior_rssm_state.logit)\n",
    "        .entropy()\n",
    "        .sum()\n",
    "        .item()\n",
    "    )\n",
    "    ax.legend([], loc=\"upper right\", title=f\"H {e:.3f}\")\n",
    "\n",
    "    ax = axs_row[2]\n",
    "    ax.imshow(posterior_rssm_state.stoch.numpy(), vmin=0, vmax=1)\n",
    "    ax.set_xticks([0, 10])\n",
    "    ax.set_yticks([0, 10])\n",
    "    \n",
    "    ax = axs_row[3]\n",
    "    ax.imshow(posterior_rssm_state.stoch.numpy() / posterior_rssm_state.stoch.numpy() * activations, vmin=0, vmax=1)\n",
    "    ax.set_xticks([0, 10])\n",
    "    ax.set_yticks([0, 10])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"freeway_example-based.png\")\n",
    "plt.close(fig)\n",
    "display(Image(\"freeway_example-based.png\", width=1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
